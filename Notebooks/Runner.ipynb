{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb236d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52aaa746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"####\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "702e2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "#     messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "#     response = openai.Completion.create(\n",
    "#         engine=\"text-davinci-002\",  # choose the engine you want to use\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=150\n",
    "#     )\n",
    "\n",
    "#     # Extract the model's reply from the response\n",
    "#     model_reply = response['choices'][0]['text']\n",
    "\n",
    "#     # Create a dictionary to store the result\n",
    "#     result = {\"input_prompt\": prompt, \"model_reply\": model_reply}\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import json\n",
    "\n",
    "# def get_completion(prompt):\n",
    "#     # Set your OpenAI API key\n",
    "#     openai.api_key = 'your-api-key'\n",
    "\n",
    "#     # Make a request to the OpenAI API\n",
    "#     response = openai.Completion.create(\n",
    "#         engine=\"text-davinci-002\",  # choose the engine you want to use\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=150\n",
    "#     )\n",
    "\n",
    "#     # Extract the model's reply from the response\n",
    "#     model_reply = response['choices'][0]['text']\n",
    "\n",
    "#     # Create a dictionary to store the result\n",
    "#     result = {\"input_prompt\": prompt, \"model_reply\": model_reply}\n",
    "\n",
    "#     return result\n",
    "\n",
    "# # Example usage\n",
    "# prompt_text = \"Translate the following English text to French:\"\n",
    "\n",
    "# result_dict = get_completion(prompt_text)\n",
    "\n",
    "# # Specify the file path\n",
    "# json_file_path = \"output.json\"\n",
    "\n",
    "# # Write the result dictionary to the JSON file\n",
    "# with open(json_file_path, 'w') as json_file:\n",
    " #   json.dump(result_dict, json_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a16cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"filename\": \"breast-cancer-wisconsin.csv\",\n",
      "    \"model_name\": \"decision_tree\",\n",
      "    \"param\": {\n",
      "        \"max_depth\": 3,\n",
      "        \"splitter\": \"random\",\n",
      "        \"criterion\": \"log_loss\"\n",
      "    },\n",
      "    \"target_variable\": \"Class\",\n",
      "    \"split\": 0.2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "human_text = \"Build me an for the breast-cancer-wisconsin  dataset with default max_depth = 3, splitter = random and criterion as log loss and target variable 'Class' and print the evaluation metrics for all\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "read the prompt and create a dictionary. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \n",
    "include 'target_variable' as mentioned in the prompt. and 'split' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets):\n",
    "[\n",
    "    \n",
    "    \"filename\" : \"breast-cancer-wisconsin.csv\",\n",
    "    \"model_name\" : \"svm\",\n",
    "    \"param\": [\n",
    "        \"kernel\": \"linear\"\n",
    "    ],\n",
    "    \"target_variable\": \"Class\",\n",
    "    \"split\" : 0.2\n",
    "]\n",
    "text = ```{human_text}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "json_objects = get_completion(prompt)\n",
    "print(json_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9b53db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01c63709",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = json.loads(json_objects)\n",
    "json_file_path = \"sample.json\"\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data_dict, json_file,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4b7ef934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': 'breast-cancer-wisconsin.csv', 'model_name': 'decision_tree', 'decision_tree_parameters': {'max_depth': 3, 'splitter': 'random', 'criterion': 'log_loss'}, 'target_variable': 'Class', 'split': 0.2}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "with open('sample.json', 'r') as openfile:\n",
    "\n",
    "\t# Reading from json file\n",
    "\tjson_object = json.load(openfile)\n",
    "\n",
    "\n",
    "print(json_object)\n",
    "print(type(json_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6557325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Modify the value (change from str to int)\n",
    "data[\"\"] = int(data[\"example_key\"])\n",
    "\n",
    "# Write the modified data back to the JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)  # indent for pretty formatting (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "568ebdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(F6):\n",
    "    if F6 == \"?\":\n",
    "        return np.nan\n",
    "    else:\n",
    "        return int(F6)\n",
    "\n",
    "def file_preprocess(filename):\n",
    "  df = pd.read_csv(filename)\n",
    "  df['F6'] = df['F6'].apply(to_numeric)\n",
    "  mean_F6 = df['F6'].mean()\n",
    "  df['F6'] = df['F6'].fillna(mean_F6)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a17f1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner(json_file):\n",
    "  # Load parameters from JSON\n",
    "  with open(json_file, 'r') as file:\n",
    "      parameters = json.load(file)\n",
    "\n",
    "  model_name = parameters['model_name']\n",
    "  df = file_preprocess(parameters['filename'])\n",
    "\n",
    "  #Check for target_variable is present or not\n",
    "  target_variable = parameters.get(\"target_variable\", None)\n",
    "  if target_variable is None:\n",
    "      raise ValueError(\"Target variable not specified in the parameters.\")\n",
    "\n",
    "  X = df.drop(columns=[target_variable])\n",
    "  y = df[target_variable]\n",
    "\n",
    "  # Define default parameters for SVMClassifier\n",
    "  default_lr_parameters = {\n",
    "      \"penalty\": 'l2',\n",
    "      \"dual\": False,\n",
    "      \"tol\": 0.0001,\n",
    "      \"C\": 1.0,\n",
    "      \"fit_intercept\": True,\n",
    "      \"intercept_scaling\": 1,\n",
    "      \"class_weight\": None,\n",
    "      \"random_state\": None,\n",
    "      \"solver\": 'lbfgs',\n",
    "      \"max_iter\": 100,\n",
    "      \"multi_class\": 'auto',\n",
    "      \"verbose\": 0,\n",
    "      \"warm_start\": False,\n",
    "      \"n_jobs\": None,\n",
    "      \"l1_ratio\": None\n",
    "  }\n",
    "  default_svm_parameters = {\n",
    "    'C': 1.0,\n",
    "    'kernel': 'rbf',\n",
    "    'degree': 3,\n",
    "    'gamma': 'scale',\n",
    "    'coef0': 0.0,\n",
    "    'shrinking': True,\n",
    "    'probability': False,\n",
    "    'tol': 0.001,\n",
    "    'cache_size': 200,\n",
    "    'class_weight': None,\n",
    "    'verbose': False,\n",
    "    'max_iter': -1,\n",
    "    'decision_function_shape': 'ovr',\n",
    "    'break_ties': False,\n",
    "    'random_state': None\n",
    "  }\n",
    "  default_decision_tree_parameters = {\n",
    "    \"criterion\": \"gini\",\n",
    "    \"splitter\": \"best\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": None,\n",
    "    \"random_state\": None,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"class_weight\": None,\n",
    "    \"ccp_alpha\": 0.0\n",
    " }\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=parameters['split'], random_state=42)\n",
    "\n",
    "  def_param = {\n",
    "      \"decision_tree\" : {\"param_dict\" : \"default_decision_tree_parameters\", \"lib_name\" : \"DecisionTreeClassifier\"},\n",
    "      \"svm\" : {\"param_dict\" : \"default_decision_tree_parameters\", \"lib_name\" : \"DecisionTreeClassifier\"},\n",
    "      \"lr\" : {\"param_dict\" : \"default_decision_tree_parameters\", \"lib_name\" : \"LogisticRegression\"}\n",
    "  }\n",
    "\n",
    "  param = def_param[model_name][\"param_dict\"]\n",
    "  lib_name = def_param[model_name][\"lib_name\"]\n",
    "  # print(param, lib_name)\n",
    "\n",
    "  # Merge default and user-provided parameters\n",
    "  merged_parameters = {**eval(param), **parameters.get(\"param\", {})}\n",
    "  # print(merged_parameters)\n",
    "\n",
    "  # Initialize the Decision Tree model with the merged parameters\n",
    "  model = eval(lib_name)(**merged_parameters)\n",
    "\n",
    "  # Train the Decision Tree model\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print(f\"Accuracy: {accuracy}\")\n",
    "  print(merged_parameters)\n",
    "  print(param)\n",
    "  print(eval(param))\n",
    "  print(parameters[\"param\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "848c7e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "{'criterion': 'log_loss', 'splitter': 'random', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': None, 'random_state': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'class_weight': None, 'ccp_alpha': 0.0}\n",
      "default_decision_tree_parameters\n",
      "{'criterion': 'gini', 'splitter': 'best', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.0, 'max_features': None, 'random_state': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'class_weight': None, 'ccp_alpha': 0.0}\n",
      "{'max_depth': 3, 'splitter': 'random', 'criterion': 'log_loss'}\n"
     ]
    }
   ],
   "source": [
    "runner(\"sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4169a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"model_reply\": json_objects}\n",
    "\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c7b3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Your dictionary\n",
    "my_dict = {\n",
    "    \"name\": \"John\",\n",
    "    \"age\": 30,\n",
    "    \"city\": \"New York\"\n",
    "}\n",
    "\n",
    "# Specify the file path\n",
    "json_file_path = \"sample.json\"\n",
    "\n",
    "# Write the dictionary to the JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(my_dict, json_file, indent=2)  # indent for pretty formatting (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
