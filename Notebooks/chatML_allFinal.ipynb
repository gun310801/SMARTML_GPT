{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "\n",
    "def add_svm_documents(client):\n",
    "    with open('svm.txt', 'r', encoding='utf-8') as file:\n",
    "        documents = file.readlines()\n",
    "    documents = [doc.strip() for doc in documents]\n",
    "    client.add(collection_name=\"knowledge-base\", documents=documents)\n",
    "\n",
    "# def add_decision_tree_documents(client):\n",
    "#     with open('decision_tree.txt', 'r', encoding='utf-8') as file:\n",
    "#         documents = file.readlines()\n",
    "#     documents = [doc.strip() for doc in documents]\n",
    "#     client.add(collection_name=\"knowledge-base\", documents=documents)\n",
    "\n",
    "def add_decision_tree_documents(client):\n",
    "    with open('decision_tree.txt', 'r', encoding='utf-8') as file:\n",
    "        documents = file.readlines()\n",
    "    documents = [doc.strip() for doc in documents]\n",
    "    client.add(collection_name=\"knowledge-base\", documents=documents)\n",
    "\n",
    "def add_sklearn_tree_documents(client):\n",
    "    with open('sklearn.tree.txt', 'r', encoding='utf-8') as file:\n",
    "        documents = file.readlines()\n",
    "    documents = [doc.strip() for doc in documents]\n",
    "    client.add(collection_name=\"knowledge-base\", documents=documents)\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "user_input = input(\"Enter the model you want to add documents from (decision_tree, sklearn_tree, etc.): \")\n",
    "\n",
    "if user_input.lower() == 'decision_tree':\n",
    "    add_decision_tree_documents(client)\n",
    "elif user_input.lower() == 'sklearn_tree':\n",
    "    add_sklearn_tree_documents(client)\n",
    "else:\n",
    "    add_svm_documents(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"####\"\n",
    "from openai import OpenAI\n",
    "ai = OpenAI()\n",
    "def rag(chat_history: list[str], question: str, n_points: int = 3) -> str:\n",
    "    results = client.query(\n",
    "        collection_name=\"knowledge-base\",\n",
    "        query_text=question,\n",
    "        limit=n_points,\n",
    "    )\n",
    "    \n",
    "    context = \"\\n\".join(r.document for r in results)\n",
    "    metaprompt = f\"\"\"\n",
    "    You are a helpful machine learning bot.\n",
    "    Answer the following question using the provided context.\n",
    "    If the user asks you to build a model : If the parameters are not defined by the user, ask them to specify, a sample json file that is to be to made to run\n",
    "    the model looks like this:\n",
    "    [\n",
    "    \n",
    "    \"filename\" : \"breast-cancer-wisconsin.csv\",\n",
    "    \"model_name\" : \"decision_tree\",\n",
    "    \"param\": [\n",
    "        \"kernel\": \"linear\"\n",
    "    ],\n",
    "    \"target_variable\": \"Class\",\n",
    "    \"split\" : 0.2\n",
    "    ] \n",
    "\n",
    "    if everything is mentioned return the json file\n",
    "    if user says done return -1\n",
    "    Always make sure you are checking this first before giving any response. \n",
    "    Also refer to the chat history while answering a question. consider info given by the assisstant only as truth.\n",
    "    The context provided is only documentation for referring information. When asked direct questions about model building remember answers in the chat history and when asked factual question about the docs explicitly, refer to the context documentation. \n",
    "    If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "    If you have limited information on something, state is and then answer \"this is all I know.\" irrespective of how much their word count expectation is.\n",
    "    \n",
    "    Question: {question}\n",
    "    CHAT HISTORY : {chat_history}\n",
    "   Context:\n",
    "    {context.strip()}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    results = ai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful machine learning bot.\"},\n",
    "            {\"role\": \"user\", \"content\": metaprompt},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "def to_numeric(F6):\n",
    "    if F6 == \"?\":\n",
    "        return np.nan\n",
    "    else:\n",
    "        return int(F6)\n",
    "\n",
    "def file_preprocess(filename):\n",
    "  df = pd.read_csv(filename)\n",
    "#   df['F6'] = df['F6'].apply(to_numeric)\n",
    "#   mean_F6 = df['F6'].mean()\n",
    "#   df['F6'] = df['F6'].fillna(mean_F6)\n",
    "  return df\n",
    "def runner(json_file, model_file):\n",
    "    # Load parameters from JSON\n",
    "    with open(json_file, 'r') as file:\n",
    "        parameters = json.load(file)\n",
    "    with open(model_file, 'r') as file:\n",
    "        model_param = json.load(file)\n",
    "\n",
    "    model_name = parameters['model_name']\n",
    "    df = file_preprocess(parameters['filename'])\n",
    "\n",
    "    #Check for target_variable is present or not\n",
    "    target_variable = parameters.get(\"target_variable\", None)\n",
    "    if target_variable is None:\n",
    "      raise ValueError(\"Target variable not specified in the parameters.\")\n",
    "\n",
    "    X = df.drop(columns=[target_variable])\n",
    "    y = df[target_variable]\n",
    "\n",
    "  \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=parameters['split'], random_state=42)\n",
    "\n",
    "    def_param = {\n",
    "      \"decision_tree\" : {\"param_dict\" : \"default_decision_tree_parameters\", \"lib_name\" : \"DecisionTreeClassifier\"},\n",
    "      \"svm\" : {\"param_dict\" : \"default_svm_parameters\", \"lib_name\" : \"SVC\"},\n",
    "      \"lr\" : {\"param_dict\" : \"default_lr_parameters\", \"lib_name\" : \"LogisticRegression\"}\n",
    "    }\n",
    "\n",
    "    params= def_param[model_name][\"param_dict\"]\n",
    "    param = model_param[params]\n",
    "    lib_name = def_param[model_name][\"lib_name\"]\n",
    "  # print(param, lib_name)\n",
    "\n",
    "  # Merge default and user-provided parameters\n",
    "    merged_parameters = {**eval(str(param)), **parameters.get(\"param\", {})}\n",
    "  # print(merged_parameters)\n",
    "\n",
    "  # Initialize the Decision Tree model with the merged parameters\n",
    "    model = eval(lib_name)(**merged_parameters)\n",
    "\n",
    "  # Train the Decision Tree model\n",
    "    model.fit(X_train, y_train)\n",
    "    para= model.get_params()\n",
    "  # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "    #accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "#     print(f\"Accuracy: {acc}\")\n",
    "    cr = classification_report(y_test,y_pred)\n",
    "#     print(cr)\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "#     print(cf_matrix)\n",
    "    \n",
    "    mmy_dict = {\"accuracy\" : str(acc), \"class_report\" : str(cr), \"conf_mat\" : str(cf_matrix),\"paramters\" : str(para)}\n",
    "    print(mmy_dict)\n",
    "    return mmy_dict\n",
    "    #print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    #return accuracy\n",
    "    #print(merged_parameters)\n",
    "  # print(param)\n",
    "  # print(eval(param))\n",
    "  # print(parameters[\"param\"])\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = ai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response\n",
    "def make_json(chat_history1):\n",
    "    prompt = f\"\"\"\n",
    "    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \n",
    "    include 'target_variable' as mentioned in the prompt. and 'split' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\n",
    "    [\n",
    "    \n",
    "    \"filename\" : \"<file_name>.csv\",\n",
    "    \"model_name\" : \"decision_tree\",\n",
    "    \"param\": [\n",
    "        \"max_depth\": 3\n",
    "    ],\n",
    "    \"target_variable\": \"Class\",\n",
    "    \"split\" : <0.2 or 0.3>\n",
    "    ]\n",
    "    text = ```{chat_history1}```\n",
    "    \"\"\"\n",
    "    json_objects = get_completion(prompt)\n",
    "    # json_objects = rag(chat_history1, 'return the json object')\n",
    "    json_object = json_objects.choices[0].message.content\n",
    "\n",
    "    print(json_object)\n",
    "    data_dict = json.loads(json_object)\n",
    "    json_file_path = \"sample.json\"\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data_dict, json_file,indent=2)\n",
    "    result = runner(\"sample.json\",\"model_parameters.json\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Transformers chatbot! Type done when you want run the model. Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/09/kkd4kch12b35yvx1xk3m4gr00000gn/T/ipykernel_12601/1112985429.py:40: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(on_submit)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab8d2c6ba8e46598397d0117d000c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Please enter your question:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b789d8c9c3433c9eae44518307961f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> what is gini index?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214caa0d70534fd5abe76cbd0e921a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> The Gini index is a metric used in decision tree models …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c196745286f34fbd90f99917b359545c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> build a decision_tree model for iris.csv dataset where target variable is Species')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcf445ecc074a21a4a5c33cbf7d7941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> To build a decision_tree model for the iris.csv dataset …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"filename\": \"iris.csv\",\n",
      "    \"model_name\": \"decision_tree\",\n",
      "    \"param\": {\n",
      "        \"criterion\": \"gini\"\n",
      "    },\n",
      "    \"target_variable\": \"Species\",\n",
      "    \"split\": 0.2\n",
      "}\n",
      "{'accuracy': '1.0', 'class_report': '                 precision    recall  f1-score   support\\n\\n    Iris-setosa       1.00      1.00      1.00        10\\nIris-versicolor       1.00      1.00      1.00         9\\n Iris-virginica       1.00      1.00      1.00        11\\n\\n       accuracy                           1.00        30\\n      macro avg       1.00      1.00      1.00        30\\n   weighted avg       1.00      1.00      1.00        30\\n', 'conf_mat': '[[10  0  0]\\n [ 0  9  0]\\n [ 0  0 11]]', 'paramters': \"{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\"}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15faf39831640c5aeb635d1d903d14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> please return -1')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f44d59c7a94dd99ae8dfc70f418540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> The following are the model params and evaluation metric…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "chat_history = []\n",
    "\n",
    "def on_submit(_):\n",
    "    query = input_box.value\n",
    "    \n",
    "\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Thank you for using the State of the Union chatbot!\")\n",
    "        return\n",
    "    # if query.lower() == 'done':\n",
    "\n",
    "    #     human_tex = chat_history\n",
    "    #     eval_metrics= make_json(human_tex)\n",
    "    #     chat_history.append(('what is the accuracy?', f'The resulting accuracy is {eval_metrics}'))\n",
    "    #     # chat_history.append(('what is the resulting accuracy?', 'the resulting accuracy is '+str(eval_metrics)))\n",
    "    #     return\n",
    "    \n",
    "    response = rag(chat_history, query)\n",
    "    result = response.choices[0].message.content\n",
    "    if result == '-1':\n",
    "        chat_history.append((query, 'building model'))\n",
    "        # chat_history.append(('what is the resulting accuracy?', 'the resulting accuracy is '+str(eval_metrics)))\n",
    "        human_tex = chat_history\n",
    "        eval_metrics= make_json(human_tex)\n",
    "        # chat_history.append(('what is the accuracy?', f'The resulting accuracy is {eval_metrics}'))\n",
    "        result = 'The following are the model params and evaluation metrics ' + str(eval_metrics)\n",
    "        # chat_history.append(('what is the resulting accuracy?', 'the resulting accuracy is '+str(eval_metrics)))\n",
    "\n",
    "    chat_history.append((query, result))\n",
    "\n",
    "    display(widgets.HTML(f'<b>User:</b> {query}'))\n",
    "    display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {result}'))\n",
    "    input_box.value = \"\"\n",
    "\n",
    "print(\"Welcome to the Transformers chatbot! Type done when you want run the model. Type 'exit' to stop.\")\n",
    "\n",
    "input_box = widgets.Text(placeholder='Please enter your question:')\n",
    "input_box.on_submit(on_submit)\n",
    "\n",
    "display(input_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression()>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what is logisticregression',\n",
       "  'Logistic regression is a type of supervised learning algorithm used for binary classification. It is commonly used when the dependent variable is categorical. The logistic regression model predicts the probability of the occurrence of the event, given the independent variables. The output of logistic regression is a binary outcome, meaning it predicts the probability of the event belonging to one of the two classes. It uses the logistic function to model the relationship between the independent variables and the dependent variable. The logistic regression model can be fitted on a training dataset, and then used to predict the probabilities of the classes for new data points.'),\n",
       " ('what are its parameters',\n",
       "  'The parameters of the given model are as follows:\\n\\n- \"filename\": Specifies the name of the CSV file to be used for training the model.\\n- \"model_name\": Specifies the type of model to be built, which in this case is \"decision_tree\".\\n- \"param\": Specifies the parameters to be used for the model. For example, \"kernel\" is set to \"linear\".\\n- \"target_variable\": Specifies the name of the target variable in the dataset.\\n- \"split\": Specifies the ratio at which the dataset should be split into training and testing subsets, in this case, 0.2.\\n\\nIf any of these parameters are not defined, the user should be prompted to specify them. If all parameters are provided, the model can be built using the sample JSON file.'),\n",
       " ('what are the parameters of logistic regression',\n",
       "  'The parameters of logistic regression are the ones defined in the sample JSON file provided for building the model. These include the \"filename\" specifying the name of the CSV file, the \"model_name\" specifying the type of model (in this case \"decision_tree\"), the \"param\" specifying the parameters for the model (such as \"kernel\"=\"linear\"), the \"target_variable\" specifying the name of the target variable in the dataset, and the \"split\" specifying the ratio at which the dataset should be split into training and testing subsets (in this case 0.2).')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what is entropy?',\n",
       "  'Entropy is a measure of impurity in a set of data. In the context of machine learning, entropy is used as a criterion to measure the quality of a split when constructing decision trees. It quantifies the amount of uncertainty or randomness in the data.'),\n",
       " ('build a decision tree model with that for breast-cancer-wisconsin dataset, the target variable is Class',\n",
       "  'building model'),\n",
       " ('build a decision tree model with that for breast-cancer-wisconsin dataset, the target variable is Class',\n",
       "  'The resulting accuracy is 0.9571428571428572'),\n",
       " ('maybe build the model again but this time with log loss criterion',\n",
       "  'building model'),\n",
       " ('maybe build the model again but this time with log loss criterion',\n",
       "  'The resulting accuracy is 0.9642857142857143'),\n",
       " ('now again build that model with gini index', 'building model'),\n",
       " ('now again build that model with gini index',\n",
       "  'The resulting accuracy is 0.9642857142857143'),\n",
       " ('can you enlist all the criterea with their corresponding resulting accuracies?',\n",
       "  \"I'm sorry, but I don't have the information to answer your question.\"),\n",
       " ('you can do that by refering to the chat history?',\n",
       "  \"To return the feature importances, you can use the `feature_importances_` attribute of the decision tree model. This attribute provides a measure of the importance of each feature in predicting the target variable. However, since I don't have access to the chat history, I cannot provide you with the specific feature importances for the breast-cancer-wisconsin dataset. You would need to refer to the chat history to see if this information was provided.\"),\n",
       " ('refer to the chat history and enlist all the criterion we tried',\n",
       "  'Based on the chat history, the criteria that were tried for building the decision tree model on the breast-cancer-wisconsin dataset are:\\n\\n1. Entropy criterion\\n2. Log loss criterion\\n3. Gini index criterion\\n\\nThe corresponding resulting accuracies for each criterion are as follows:\\n\\n1. Entropy criterion: 0.9571428571428572\\n2. Log loss criterion: 0.9642857142857143\\n3. Gini index criterion: 0.9642857142857143')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
