{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "async_ai = AsyncOpenAI()\n",
    "ai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "prompt = \"\"\"\n",
    "What tools should I need to use to build a web service using vector embeddings for search?\n",
    "\"\"\"\n",
    "openai_client = AsyncOpenAI()\n",
    "\n",
    "completion = await openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sklearn.tree.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "async def completion1(prompt):\n",
    "    completion = await async_ai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= prompt,\n",
    "    temperature = 0)\n",
    "    return(completion.choices[0].message.content) \n",
    "\n",
    "\n",
    "    \n",
    "async def completion_from_messages(messages):\n",
    "    completion = await async_ai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= messages,\n",
    "    temperature = 0)\n",
    "    print(completion.choices[0].message.content)\n",
    "    return(completion.choices[0].message.content) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append(\n",
    "{'role':'user', 'content':'what parameters i could set for decision tree. '},    \n",
    ")\n",
    "response = await completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['462fa7440279495db9bb93add2bf4b72',\n",
       " '0c4e9d186b47476e93499e3602347fb1',\n",
       " 'ec6e2723490d4d2089e9f36f6b90e331',\n",
       " '1890707a84af4d4e9c5aa5129cdad6fd',\n",
       " '1b8e437a6dc5484d8c4e410491f53424',\n",
       " 'b3fcb3081ccf495e809df83c6bfbd6b1',\n",
       " 'bf00e3c026e04cc6817681a5b9d20d03',\n",
       " 'b2059caecf144964a352fb96ad25f64c',\n",
       " 'b5b8ee69ffbf4c4c8efa66f7a0f9e48d',\n",
       " 'b31ccd8017ff4fcd8348f3dbfb918fda',\n",
       " '1ee4f4a84a3948d5a14b1ad8c7e06791',\n",
       " '509b060ebf00452e893feab6700b70cd',\n",
       " 'aa04e58105ec4928889cbbbad092b863',\n",
       " '4abeb801c0a946968914cd2990d4eb61',\n",
       " 'e55a82ee8b25435abdac8a5a19785e16',\n",
       " 'c47401c7f36a4ee69a607914f080f50b',\n",
       " '95429603130d4ef9974e761a30f0744f',\n",
       " '1ac669622d1f47fcaea28b17e44b14e6',\n",
       " 'c2cc40654064411a889338de79c9c620',\n",
       " '638ba9d9017440659ef58e2f26d6cc35',\n",
       " 'ceb2cc4f92c646cfaa37fbaad8d6c653',\n",
       " 'e34039c8640b47cbadb786f107f351d0',\n",
       " '198641cfba4e4d4fbf3a233a7e9a9bdb',\n",
       " '7c77057e7ed24e4fb02015787a4e52e8',\n",
       " '1873eda9959c464cbb8638b1316bbfbd',\n",
       " '7eb4de0320534bcb9b58d787074a86f8',\n",
       " '40e74f7e5a2e42248bba0886d477ca70',\n",
       " '12a81b75b0ed45a88c741fb2f4035c94',\n",
       " 'faf6fffbabd3408b8a39ef21e500aa66',\n",
       " '84d46d09d15244978d6057055b11ef1f',\n",
       " 'a1b47f78bbf84d7f92fb74375c7a90be',\n",
       " '94677ca713ec46d48f7b7b9ea6f77163',\n",
       " '2fbea20cf6f94170ada47cd88b8a830c',\n",
       " '5e136f6bae3f417b904bf84cd0ad00b8',\n",
       " '60ed17a2143649c7bdc0fe64131f9990',\n",
       " '4930277943c949938cf2c3e397aa4f11',\n",
       " 'acec3b8569e0442abbfbe898debb3e4b',\n",
       " '5bae3aa4789b437b845d93fcd19b62ae',\n",
       " '5bceea63eeee49cf878085dd54f20318',\n",
       " 'ee3bc1b0c3e34398ba3012657418161d',\n",
       " '9e403d073a4140d09805077f2303fdea',\n",
       " '50e3f319da3c461490cd4eb95b85041c',\n",
       " '693dc6862bfd4405b7c53d344a92dd32',\n",
       " 'cfafdc11f8bf473a93e76e13eee5364d',\n",
       " '04a0a5db357c45dba3c97c1bccd8f443',\n",
       " '842f5636e2ad48aa9a93177da34faea7',\n",
       " '3511cf4c61344773b88875137afa3364',\n",
       " 'ec6d6c20733044849efbcc61455f1a00',\n",
       " '12ee9fa3070b499ab50871e4628c50e9',\n",
       " 'd523446c0fc14a0c8c9937307aef02f4',\n",
       " '9c6661179d8446649fc3c609a594e478',\n",
       " '3edb2ac4ba3249de99a39387102f770d',\n",
       " '8b891d391e874450964bb5f828346b9f',\n",
       " '697d3b6077af4c28a4a38c5d84cc1813',\n",
       " 'bf2666084c1640c49ea4e48cb8041c72',\n",
       " '39bd63fda1e14bbc8fed6a1b7d04f582',\n",
       " '767901d315ca4cf88309f63924a8e530',\n",
       " 'fe844329fdc141e69003e4444db5b22c',\n",
       " 'e0dbffe4df2f46588e58f315e345d6ef',\n",
       " '667f629c0e2941da8c23a995ec252f05',\n",
       " '8235c6cf4a024eb1905d4686123bbd6e',\n",
       " 'a712a34e27334aaea8794f4b2c659557',\n",
       " '12110a29cabf4d4fb34e0bcaaaf4f2cd',\n",
       " 'af3d4d570cd746c2a55cc5036d5c3b4b',\n",
       " '58e83d4bc4c24deabb017e68f9102424',\n",
       " '17f489c94392467bb1b2d49f8447e23c',\n",
       " '23ed515717e44ab38811856d877a30c4',\n",
       " '5b527a5c5e9740ac9f614d41a260f968',\n",
       " '22d9be17e3a1443d92743b84b22aa711',\n",
       " '1075e48772a84fe4b98a517c4e1a5de4',\n",
       " '6c68687614d94bcf9d773cb8fea18559',\n",
       " '4d90538d0cde4e8eb4e4aabc18d25e4c',\n",
       " 'e98c6fe9e9ea472daaa114a67804568c',\n",
       " '388cf29adbb34f3f9484a205b0aafac0',\n",
       " '84ec7314d9a94ea3965edfcec123814e',\n",
       " '610f706b719248d4880367814b9f5a6e',\n",
       " '7ca4acb8a316406a8eaa3e3a874d4f65',\n",
       " '9962e38e122849f2973377eae3d75a80',\n",
       " '384815bf7ee54a449dae3f95a95630c1',\n",
       " '5daa2f430221453ca9cbb62d8d7c292e',\n",
       " '4ce3f5d0d3db4b2f81f4424b75a49526',\n",
       " '32a86651876c48dcad9ecdded1e99606',\n",
       " '8445e609e7c84bb4b81c32a60a803cc2',\n",
       " 'cc214b6e596f43b28b949fbcb3d2e71f',\n",
       " '647f58e899bf4fe692bcf50a91021b74',\n",
       " 'c13765c3253b4d6a8357f5ede178ab85',\n",
       " '92f5f948a4b249f39d042cd2725dacbf',\n",
       " 'df040bb3e6dd416e8778da2e05f742f9',\n",
       " 'b71c4eadfe1944df904712701ab4173b',\n",
       " '221a10e9d68e45bdb79d96a55a746361',\n",
       " '9cc03ba41b2a4311bec0e1b0bf0876d6',\n",
       " '6ef74883f4dd4b818a6c04afae00ad1a',\n",
       " '59031fb457a943bb95654a2a786b03d7',\n",
       " 'c6f6167a2d344c7581eae2970fa18685',\n",
       " '4b4233ba1ea642d38a096f8c3094ee31',\n",
       " '4c86a62e41d34d4799bb143e4ab9cbaa',\n",
       " 'd9a86ef9dbcd49bd8c2c58b224df2a63',\n",
       " 'daaa2639a3804949942f442f6446ee3b',\n",
       " '8a2be264589d49e29a629c8f129b4f8f',\n",
       " '45b0a88fa65146618b11bcaa7c3778b8',\n",
       " 'df39c66de1f34c3ca113ecf39355bcb5',\n",
       " '149def873a974b6494a755fc3f77bc14',\n",
       " 'e8e806da47da45faa461364f50b435d7',\n",
       " '9dd417c00daf4c3a9ba0659253ad4e9c',\n",
       " 'c37d12ec5abf4bc79ab827a5d92a2225',\n",
       " 'd01fa4d79749481d93cc470a977c1d00',\n",
       " '8e53f10e79294b48995a87cd1cbb1c8d',\n",
       " '68a361ef695d4d208d03c53cae0aff08',\n",
       " '721c86ab71c346ac9b9c4cf4d526f64e',\n",
       " '97980e7d9cbd45eb9614db9b7ec3311f',\n",
       " 'd7efe422d3a14447a2d8f0a3d8132aa6',\n",
       " '972396398c3d4bd18c8009733b9a5a9f',\n",
       " '4fdd85e5858342ffbd92ec9e3252d188',\n",
       " '1572c13f7c3d4bab933342d72d16f111',\n",
       " '7836e60abd964f6bb733669f482f54b2',\n",
       " '4b7dabe19cae4c81aabcac20b7b3049c',\n",
       " '8e6fe78aff2e409c8301737fa01d7162',\n",
       " 'cd9f12e6d1be4e1ead1b449c1508523b',\n",
       " '40262afad74e4336a5e8ff47a887ff85',\n",
       " '16a6a196c34a4d0a98b9f834dad2b8a1',\n",
       " 'f3c78cb6511a448bb2f97f9fbfdd3598',\n",
       " 'c1030bf743b04f1db70b128b980c5950',\n",
       " '27b5819369974013986ffa0801a0f9bf',\n",
       " '1e8500cb1296427f8cd36b8f9217bebd',\n",
       " 'f208b284bf584f00a0b9603c7b07c438',\n",
       " '8136724174b74ace990f7ab44ec3354c',\n",
       " '0cc1483909b64876bb512f1b45b294cf',\n",
       " '84eb20d87cc94d908b4f9398b0b63480',\n",
       " 'c75b3c13f0f044939222f95348f4f7a0',\n",
       " '7736900807b1455cb408eb688512ba13',\n",
       " 'eb23e2b6cbfb4a1f91861730d239df43',\n",
       " '11ff6c5369c7443b84edbc07f1367e03',\n",
       " '56f1717ceea84cb1a9507e92e17cf434',\n",
       " '0ba12b65398e4b72a58874cb6b237b8b',\n",
       " '14cf7d497a2d417185db1bbc2ca64461',\n",
       " '5395e2dbaadb4a66a79a74da9ce898ac',\n",
       " '255d71cddbfc4bb5b72d29cd52b487f7',\n",
       " '763d774bc27a4c7ca9f44fcfe6232d4f',\n",
       " '1664b156880c4f70a5c2cb3218e256d3',\n",
       " 'fc2c52b3fa47420993cf5e7c8e8ed2dc',\n",
       " '48b6fb8ed5174771a65a08583d7c6fae',\n",
       " 'fd7d90a1079c436da5e2f732c11b3629',\n",
       " 'fc29a922bf8d4cf4ac69286bf80955bd',\n",
       " '27cc2a116a7a40079140731f6b302cb0',\n",
       " '53e70ad406ca4442bc2586f6998e2be2',\n",
       " '41a55c4d56dc46a7a00827bbd86b9cff',\n",
       " '1b291859c2834531b30930ba280e9fdf',\n",
       " '27510514deba4143af296254476a684c',\n",
       " '4bedbe63007f49559e97984afc0863ef',\n",
       " '1753ff05a40d4645b1f9608097158879',\n",
       " 'c78e8d43c8b04204a9fde120080a885d',\n",
       " '61bce7a876f340ba83a7fc0f74435f82',\n",
       " '765c356c071b43bf8d3b6d0ea8ac6c1e',\n",
       " 'af88b845ef95469eb86006ab2717bcce',\n",
       " 'ae3561c2a584425f8f038bd830cde627',\n",
       " '8449758dc9c44b17b253afd5cf943a29',\n",
       " '413453411e11474489bd943837b66639',\n",
       " '21e77c44d0344dda9a437c02786c9ef1',\n",
       " 'fcdfe9984add411d9285d6d3e4c87b3b',\n",
       " '56282c4bdfd249109c5144a83eaf5df3',\n",
       " 'f9de0c406e0740bc8a3c2c5d75797496',\n",
       " '592f189ddb76477cb877e9744c6ee5ab',\n",
       " 'b5ce17d3e18a439a87ef199ff9fd802c',\n",
       " '2e6d7c1d370e419982bd259987a21186',\n",
       " '0f063596d52741a4b911bc7dd23bd740',\n",
       " '6bdf4e4687a54c3fadfe7353915671e5',\n",
       " '9dc003fbab0f41f2930da683ab19c925',\n",
       " '3827534114004bf284f33e433f70b16f',\n",
       " 'a4c2822f90be41259814135d46889fe1',\n",
       " '03ef96ed18184e1cb070ee56d1f75b38',\n",
       " 'eda3d6fe57e746ce8be86489ee2b0519',\n",
       " 'f81b7c85c1934216af2e73999007e9d6',\n",
       " '6c29ed93739f4905afa9f8c39b570c4c',\n",
       " 'df846eab592343fb8e7bbe4984f82e8d',\n",
       " '84ce92d9f330478b946f0432169cdf7c',\n",
       " '63b25950181642a6a6dc40d95d92b4d8',\n",
       " 'a33217854a5d4197b247c687b8109217',\n",
       " '3a2b4ff096c84ddcb21ad9beada9d606',\n",
       " '7b90639bf4df4b74b43a78c2a7e885f3',\n",
       " '8273ecf6648245099e5aca2ec8855cbe',\n",
       " 'ced488fda94c44729e734c653c1982e9',\n",
       " 'c1d4c269228d45ab93dd945fb6ff6a33',\n",
       " 'c2e5bdedd89d45ff99cae16455c7e99b',\n",
       " 'f6e98ec538cb4eb9b068f6d856e5ecea',\n",
       " '352b9800773545b0826c10d8a486827f',\n",
       " 'f948014188a74f518862fae7ec783878',\n",
       " '34783d342be044e68c58799e45040502',\n",
       " '3c907d6f07fa44c5a027c8153abd3350',\n",
       " '8394507f46f9480cad0f8cd736a8802c',\n",
       " '3cf00ba19c924a1da716d5aec711f104',\n",
       " '1460ef3bcd3246c19998b8a801b10b43',\n",
       " '4e2315f089fd47d9bea804162cfcec36',\n",
       " '552a92a00ab34156b9d4e63d0a1e08b4',\n",
       " '8841568b91b14ab0ad2a924b3bfa7a25',\n",
       " '3a01a519e5b94ebeb56996d8602d98e1',\n",
       " 'cf751754c021482c9e0c2f9bcb494a2a',\n",
       " '20bb784350f84b7ea6f2aaae3d36569f',\n",
       " 'e192a94d57074bb6908965279ae23124',\n",
       " '6ba83de184dd4dfe8bc54808a796ef57',\n",
       " '36e6942a90a043e98e33bca8413943b3',\n",
       " 'a2ab92a98c8640c1811a454c0f5e9d2e',\n",
       " 'b76ba3b03cd84ea29178954b2b8210e4',\n",
       " 'e8f1192e97f8419d86ed1c7d65fecd41',\n",
       " '3fe0fd7d27b745feaece263bbc91fa53',\n",
       " '4b09a762194249c39d306daf2c1eeddb',\n",
       " '2aabe458750f4a378234484694bde960',\n",
       " 'c8ec8df9bb47444da0fbc82665e0f605',\n",
       " '5b48a2d260504c8eb02508002e45e9f9',\n",
       " 'ab1eafdc565c4b7bac6db365f3ffa1f2',\n",
       " 'ae8c1dd9bc16415d9c03f50cdf5ccb2c',\n",
       " '8ec2deed4d6644a98f1ebcf7836969ec',\n",
       " '43933268b9404fd29fdcc1c15eeb25a5',\n",
       " '197f9e8c6e614c91b153da9c91880b9a',\n",
       " '644a72df010b46828358eb727d364e08',\n",
       " 'ed150502b2d44db3a898ad511a8a6bc2',\n",
       " 'b9decbc09e724cb69d849b60d683714d',\n",
       " '2e591afdd5e845229e0bfde50c4f5719',\n",
       " 'e94e89ba99ba4c5a918c58afa78b927b',\n",
       " '25517a1da03649b6b8d470f2b5e45f1f',\n",
       " '5f3262de34794fd29bc9e7914c80baac',\n",
       " '9c60dd40ac5a43a4b2fa7a7b01f1d01d',\n",
       " '93720a6a47fd4b84bf8e86c4b80fbedf',\n",
       " '5593ba8675974159bcae610b8d8b02b6',\n",
       " '4a6ff83864594bb09b338b091cdb122f',\n",
       " 'cf304994e0ea43049ca01b4b3e9d583e',\n",
       " '01954d9bc1334e118324808aa35c83b0',\n",
       " 'e763f42567fc4e6184ec11c6f3d07887',\n",
       " 'eb87faedfb8248a296ee5a3464c1ae91',\n",
       " '15199db597fc4e9783d347af3dd8012f',\n",
       " '45e7e81581cf4a5e9c2957110625edb5',\n",
       " 'b90182833a41441c8bc4f5b90c00ccb2',\n",
       " 'de5dbb7577c54f6f855aa632e6ca2b92',\n",
       " '4178d11baded4c83a0b248d28389afd6',\n",
       " '12f4a24ad2df4c829e34ff9b4e2023e7',\n",
       " 'fc4b67bcd94f4bbcb885c92c06fd2efa',\n",
       " '7b86c6856d69427583346fdf959fb214',\n",
       " '4b2b7422b88f479d99f5c861f1b5481c',\n",
       " 'd1d9bb63bcfc446db95e9554f2dd933b',\n",
       " 'c8c1d039fc0440e1a80c001b5ee6a852',\n",
       " '166ab8a2e6184b68bfe7af1a7ee08c32',\n",
       " '9dfae12f0e014f269394bd672cb2bad6',\n",
       " 'c875f5f1f904407a9d9c362d97b7371c',\n",
       " 'ca4141caead5420ca7c27a32d26a5ce8',\n",
       " '1116c896fe074e86ba0cf86fd57d4ae6',\n",
       " '60634dc4108d4411ae34778a86e02fd5',\n",
       " 'e0626576a207485aa419ae27b0e6e845',\n",
       " '36e0b90c95614ca68a3d2b607e49cfdb',\n",
       " 'e4fab1f8c3a44d7494984c03ae7484ca',\n",
       " 'a5b829e97a8244519e84f9fa91a02d23',\n",
       " 'e4e3629da5374b02b95a36c4ca9a2068',\n",
       " '25820982eace4db5b234227efe3914db',\n",
       " '90122878d1d7412182df6e728689542d',\n",
       " '6459f3c2d40a4cd09772c7018959c669',\n",
       " 'be9d8ed0547649e4bca555aeaf7cfef5',\n",
       " 'bc16fcd7a10a48f9a153299a348b676a',\n",
       " 'b0fb6bd896784358a634b330150883a8',\n",
       " 'c00ed5778cee47f7a4022ba700ca1436',\n",
       " '9d1dbf83c967428389db9326d8f85afa',\n",
       " '1ce628945aee408282f65960575b932b',\n",
       " '999246a72b2c49b8af423faf928a6e73',\n",
       " 'c18571814ad24dc2a6a58a4892e631e0',\n",
       " '5de99ed29d214e94b89d7272c46c8fa1',\n",
       " '0afc5b276d344a60902eb455a4a9f69f',\n",
       " '6a851cf2b2604b9a879a8ac7c3fd2edc',\n",
       " 'c412dc2e21b74cd4b9607738dd983f68',\n",
       " '3391c9347ba84b63a06448d497765c98',\n",
       " '25cb1d0fd7b2460895536dda01ba6150',\n",
       " '611d263baf4a4cdd9fc2619e3983f954',\n",
       " '3843308d88774a19b6c3d92a9ad68193',\n",
       " 'b3f3865a168f4ba0884e23aed3055fdb',\n",
       " 'd14387ffed794585a89b70e869121b40',\n",
       " 'f395103a584b4f8cbe15631c6021dce2',\n",
       " 'f2f42179b0504990a1c99e121e80d5a7',\n",
       " 'efee4278f7114aadb63afa014bdb643d',\n",
       " 'a08726604049485b940af83fa0d14a10',\n",
       " '50433dde849f4ccb880bf6f5d140d0ad',\n",
       " 'a869deb8c4a4457780b40956206d213d',\n",
       " '4676e246aa634a39b908047310198fd2',\n",
       " '503256654bad46c79d68da2a92360473',\n",
       " '673223b801194529bbbbd847e0ffe7fb',\n",
       " 'eca5d068e5d34b2a85f22078b3118c23',\n",
       " 'c05044a89ed54a6f9609cfc169bf9a7b',\n",
       " '2254ef734906440a918d9f5736a492d4',\n",
       " 'ff395a97969b4272a2e6cda18bb5bf86',\n",
       " 'eddff1893bef435892b9a36d21722c6a',\n",
       " '087504ee0800463ebc55572f23c2a008',\n",
       " 'c0e9d2d795a04e2db088997ec0168571',\n",
       " '9994bf6093ec4c93b98b2215ebe357cd',\n",
       " '7ac3047e3d0141729020d7e2cbced59f',\n",
       " '9254e13d4f394aad9c5a92d55a517a30',\n",
       " '865c570d067647ebba900cd13990f821',\n",
       " '16361b5a0e2b422f8c7af58d376e70c5',\n",
       " 'ddd816229ac4437cbf97c7919440ddd0',\n",
       " '11749f868fc346b7abc47395ee7cd794',\n",
       " 'c6a4cdf7ea9346f28f71ee3386a8bb53',\n",
       " 'a677b850fd494074b623fdf1935f1d16',\n",
       " '7c1fdf90de1342bb99768e66ffdc9560',\n",
       " 'aef72d7c4d5349d9b570ce41dfe7ab5f',\n",
       " 'd3d0d862863c4c7da3381b235e5a1666',\n",
       " 'd3715a08451a47378260d122192d5298',\n",
       " '0a759aca2e7d4b728552a25b59b90ec2',\n",
       " '1c7bbc650b5d450190edfb1bdd10f785',\n",
       " 'c45794dfec5442da883af045f1037531',\n",
       " 'ba85994ca9364fa386f4294d7bf755a0',\n",
       " 'fb4c1decec2f4853a6b6bde198d9e1e4',\n",
       " '90db9f96d9014ef783d772578bc52357',\n",
       " '2f078d90094a4efb93f60b42381089f4',\n",
       " '6cb91877138342a6b313cf00affc804e',\n",
       " '43a5cf6ee148485fa2af00f3ac62c2c6',\n",
       " '9f155689381a4b2e9cd6756cf8fe5166',\n",
       " '200213dcbf584662b924f09494edb8d0',\n",
       " '08bf0f1f1dea44abb2aabc3b4b111906',\n",
       " '21292445ba9a4e99bd45407d11551b96',\n",
       " '2216dcc96a444b6b86380e3a8e262d1b',\n",
       " '08a68afd101a4c379f40c0a53663b7ff',\n",
       " '8f89dcfc8d1b49f0874ff44e2188603c',\n",
       " '3d3d5f47e9e6470cbd3caa5fd88c64c8',\n",
       " '438c94efced04272aae1ff98a136ea80',\n",
       " 'ba496e86c16047528257822e765350b7',\n",
       " '6a33233438da4b8daea2079822a520b2',\n",
       " 'e3bf4e1671184216b81220e5c45069c3',\n",
       " 'fe2ee56619314f0582667507bfe180b5',\n",
       " '47b3b203756748d9b266c303c175d37e',\n",
       " 'cc2fca23431b442a8ef21e54a27547f8',\n",
       " '5407460f2e46422aa34bc07a1f80192a',\n",
       " '91760f4fb76d4fa6a310f81e285aba4e',\n",
       " 'ceff9bd6ba0f43f5b66ee36960992fce',\n",
       " '5d719b85c0604cf4a77162e6cba8af4c',\n",
       " '8b4a63d74e26495595b66ada24097e9e',\n",
       " '2234ef03e7744635bd27427bc353faa3',\n",
       " '822f882441014e96b087158b402be826',\n",
       " '1055bb962c07484a9ff878e60822b53e',\n",
       " '86a78f16bcb74f079644899915d27706',\n",
       " '5497107c85d543d280ea7ab193b9f4bb',\n",
       " '9e8fddcff797413a9ba8ac62fe004b3d',\n",
       " '0c55d637e4ae4f1e9a920e1e2a9309c0',\n",
       " 'cb3cfad8d1bf41cbae496dcff503dbf8',\n",
       " '798cae65248b4061aca8ffcc88dbc792',\n",
       " 'e1d22fb96cd0421f94970d5f0c7de4cd',\n",
       " '3ef0773f8db648bc86de647e8b1ad641',\n",
       " '2ec654e1fb5d4ee2b2da4920070b4acf',\n",
       " '31d2a1097b324a01bcd3cb7011892bbf',\n",
       " 'f02e93d5f75d466f8c29da2876d1aca9',\n",
       " '44c38c43696d4fd785c7b15ad5efb9ea',\n",
       " 'e3992e40a8014862ad35b93e68a8e96c',\n",
       " '227b4588d79d46b3a86546ce9300af4b',\n",
       " '8c3717c762684f5d959fa5384a92934a',\n",
       " '41db38dcf18049be980b99e9ef37f29a',\n",
       " 'eeb1bc5c8ffd4c87aa4e79fa1c726460',\n",
       " '9ba68cc9799d40779d000844d2b8f28e',\n",
       " '98a997ca76884042bc879e942727d6af',\n",
       " '53ffff6a1d85456c9c70256e9c1d019b',\n",
       " '6d5f0b8f6dfd435aaa10a66204e41140',\n",
       " '995aafed4a354cc4825b756422afa159',\n",
       " 'c835c46651594a258d6cd0de021aaa79',\n",
       " '302e7fcde6864ce5af47894e581b2f90',\n",
       " 'd6a17b8dbc744a24b7f46a7e54219572',\n",
       " '3dbd012d357c4a31a23011d3a3af53f7',\n",
       " 'ad5c39f1f38e4fe79f4a336520ca7f35',\n",
       " '588e2b077e7a46eeb56796661435f971',\n",
       " '6deec5b35040493189ca26fba26ad8bc',\n",
       " '0d066c430a4b499da953517e674fe065',\n",
       " 'bcf2d5d14a8641e390c6f2057493ffe7',\n",
       " '3cb5588e221f41c28d5e6d7d2ca77e17',\n",
       " 'd0495cdda3ab42d7b416db23126d6583',\n",
       " '1c992ed255074b3b95b3102b49f60692',\n",
       " 'e106d508ca384891a228db72f310da74',\n",
       " 'acb1080a029a44a3b1559606131bc014',\n",
       " '50d141610f55430ca06e97085591ed33',\n",
       " 'a4a6ab0af3184bce9e68ab101d0ab0bb',\n",
       " '2ff0d9b89c264a9fb32323942c8cb4c7',\n",
       " '340a50058b244b48bb4fe39108628f29',\n",
       " 'a99e68ef0ede4792aedef8ca10192c01',\n",
       " 'fe4ce1bd0aef4515bf51f6a3e80133f3',\n",
       " 'f0996c7b84234f1c8fb758a57a7a9eec',\n",
       " '912f290e616f4905b474c00961ece14a',\n",
       " '9d8ea1668df94e2c9d2a93672b72ae47',\n",
       " '533e4361e2404a938328e63adca965b3',\n",
       " '9ba5b15edc0f432a8495287a2222eeec',\n",
       " 'a8e2b58744d6494fa7c2e1a54ee824d7',\n",
       " '92ffb87106e54370802c30126c271ab5',\n",
       " 'a7091f4a6fc64b96b60822a6493d0fd6',\n",
       " 'be8ad7c179be4a46ab1d8bfceb9027c6',\n",
       " '7eb8886f86f644699bc8b8ba43641e8b',\n",
       " 'efa8bc1eab4f4872a8029b3e6fdedeab',\n",
       " '72afce8347054c0fa01e982f3946d4e3',\n",
       " '8c6ebc061015464d9089d9d2b71c8b56',\n",
       " '4b0753116f984cbfae2c0805de335b58',\n",
       " '2366bf2f1a054173acddda289536ba7b',\n",
       " '174142c863bf487bbcd4c34c913d9025',\n",
       " 'e1808c625c65472a82c311aae63a325c',\n",
       " '88c9ce2dad2442f3a8a1da2a7a7d66f8',\n",
       " 'dd6aaf628dba4574b2128d558501cb34',\n",
       " '5f7c1f5233014358b42af2fcbc8b8674',\n",
       " '2e99c0e4ff834cabb2fcef9b9dbdbd8a',\n",
       " 'ccf8b329b37b408d8813788dafed9651',\n",
       " '14de19be64e5438bbf8a2f633ba38081',\n",
       " '68a78cfbeed3436d8c36fbfd7422c547',\n",
       " '0faf6a2dc7334a138df66db2351625ac',\n",
       " 'cb5e44a8001d4ce0abcb7d059450bd5a',\n",
       " 'f58d233b4f884b32a7dce055fccb100a',\n",
       " 'dbc6fae34eaf456898fac1f822f9d770',\n",
       " '4e1a9bb7665b4cb39f2c68dc59042c8d',\n",
       " '3013da90bda54da3befbfe9b42bc6c22',\n",
       " 'f1f63a8d2d32478888848fec777c5139',\n",
       " '7b96d0401eb048f3ab2c2e3fe2fec6e2',\n",
       " '251d1e2c7c2649638fe98c63079f916b',\n",
       " '44138419bd0842b39ad7d2dbe8b3291e',\n",
       " 'ee95ed575aa0460abcea9b0e183dab8d',\n",
       " '7abb484e91944ec69f6ea3b9b2a56eaf',\n",
       " '1433ce2e332f4962adbb841b4fdc7a21',\n",
       " '94dbbe681b1b4dd59f3f223de8e3b2e7',\n",
       " '0b8c3138dc0044aea865aa9ccb6ff2e1',\n",
       " '152b754c44cb4930a6203c0f8c20c948',\n",
       " '3d013e155ea04ce08aa791cd31c81e4d',\n",
       " 'fed346b84cd2407a872c8ab337993a66',\n",
       " 'ea188f81abb94720ac2c35eb2e0c5c47',\n",
       " 'e5ef0e085b57424ca35cb5fc8ae1984e',\n",
       " '6bd608c510004f5ba8110b39b6d3a990',\n",
       " '70debe024f6148359cf5a95cee9d36f7',\n",
       " '947d757cb1524741a2c09a783303f6a0',\n",
       " '09c311496f584697b6c8ac01d1f7a9a6',\n",
       " '2e40b4101110427c9d30bf45d2aa4124',\n",
       " 'e580ec2b89eb4b71bb763f673a1bb4c8',\n",
       " 'f09eb82c40ed4f24943e6bc4df7a8f1d',\n",
       " '91c9162ad9da4172b932afa8e9e5f506',\n",
       " '416567786076478bbfe34f2b8f70b390',\n",
       " '7b5efe34e7724e72ab4ecfd3a84249e7',\n",
       " 'b8f54881121d4fd1bc014b771c8e58fd',\n",
       " '0249834d22304eeab8e3ec685d1c7246',\n",
       " '92385e21833c4494960d228f40c8ec13',\n",
       " '73108e7f0e8c4643b29cc962da5ad482',\n",
       " 'b691c3ce1fd64cbaa50ae71797fa821e',\n",
       " 'd34d3fc8964247ed8c86b20402779639',\n",
       " '1d12ca53acaf48d29baa32b9afcd9814',\n",
       " '3effe0dfccdc4505b2c750dffa7e6cc3',\n",
       " '7681524c6fed4485b3d1a99d31b7ce4a',\n",
       " '0fb150c1f6b8422ba117737001bbab0f',\n",
       " '47ada663f0fa4cca8d6c7ef7e8bf19bd',\n",
       " '2c1b4868e2cc4f72b5e81656c8fed5ae',\n",
       " '5cce4568ca0948cfbf307dac100f2946',\n",
       " 'bab0217eaf99423dbb0e89eaff014fe7',\n",
       " 'e7ea8c1a79ad468e9953c6338fc493f9',\n",
       " '64f2adff89954eaca458693a20c587a4',\n",
       " 'f4dd77b4d71248f4919af85410890264',\n",
       " 'e6d09411e04442c488729277afa8f137',\n",
       " 'eaff14331b0247e1aae0ae97ca2cfb54',\n",
       " 'af236c52867041caa1aaa567e0ad36bd',\n",
       " '29fda6f17b4148f6b615cbec8e91358f',\n",
       " 'e95f4db786bf46f4a21254bac8377b23',\n",
       " '291fdc85431248d49c9071c233e8fb4a',\n",
       " 'f3c7ffd37d014c678d4315941637b137',\n",
       " 'd6feefbb63ec4cf9a449129840d185b2',\n",
       " '218166737d824950bebfc2af7929bfbd',\n",
       " 'bcb946bf770e4e2ba9498dc58b2a8dfd',\n",
       " '715c7ef8a9674062950577c8ef58f7e5',\n",
       " '5966f43b02694a19a1edd61d443f331e',\n",
       " '525e3c317e78430c9365328d33e7fa9e',\n",
       " 'c6f258f4205c4a6d964d7e7f932eebf9',\n",
       " '6c530950066e438882bcb85e6c53b335',\n",
       " '0b6af6523c914f38b7fba8ecc9472286',\n",
       " 'fdde59be77f2408d95ff42503b18ec2f',\n",
       " 'f727d9b5fafa4441bd9b9b6b16e4b09c',\n",
       " 'c239138688774bcfa100677b128675dc',\n",
       " '4321b7ead51547fabb04d3c6755710b1',\n",
       " 'a5e8b700df774a99a7ec3b656a159183',\n",
       " '8963f7d79f1146248400dbabac2149ef',\n",
       " 'c89e0ac9a9294f60a26b77692322d737',\n",
       " '40c606c4c8fe47588f2a6ef43042d783',\n",
       " '15d47e448096455587e64c4479593006',\n",
       " 'b6eb48e3e09a4fa6b9237a842127d70e',\n",
       " '9949f6e11e7c491c9ac5d2531cd1c35d',\n",
       " 'e9aa613b8bc046d2bda20dfb04220fde',\n",
       " '25bf3456c20e43c8bac7223121e0aa7c',\n",
       " '4f13cf5ed5a14c73a38ae32841a554c2',\n",
       " 'fd07fa4658b346a7a22672ba3f71fb73',\n",
       " 'b5d627573cbf4e5a913ec9bb76dc9df5',\n",
       " 'f2447b52b7b74bcd998f0079ca5a66df',\n",
       " 'ec8fbae5439f46f3aed2d39fe84ce75f',\n",
       " 'b7629ce7a33e4d0e9c62a1e480659577',\n",
       " 'eeb048e971d447ae8f60b05c0bebb5ad',\n",
       " '2980669c2b7b4f878de2d9653101e7bc',\n",
       " '4410b33c632748cab740c6e7de21c0fc',\n",
       " 'b1466af123414da583a1ba350dd3e0ce',\n",
       " 'c253bc3836e24b6186382a1427910ec1',\n",
       " '010a063819db48ee930332ee8c859f76',\n",
       " 'dc400749b24541c1b2d100e84861a89f',\n",
       " 'e732c4ea4e484c15971521800e35850a',\n",
       " '5415c1c3f1c140ceb71bd7614cf0b616',\n",
       " 'b3ac1f50b3a94e2b924d005bd4ebe4ee',\n",
       " '81104bee4b584a3e84c1053752accda4',\n",
       " '38a2bbf405c54ebeb1b4cd69c86e554f',\n",
       " '2be90f54e0e44329ac898726ff75cca0',\n",
       " '044181c4dafa413cbde710234a31ceb5',\n",
       " '20526f73fdf742cf95524b8306c81be7',\n",
       " '061d7c9e82544a0e99559ef1fc6a70eb',\n",
       " '084a946ea0e24342938282906561cc26',\n",
       " '2429fa46533d43aeb18dbebec3401d0a',\n",
       " '009d332fbf98459a9240cbb5da6f3bb6',\n",
       " '65b906dd1dfc496b8e494b406df730c1',\n",
       " '9386ce5dd5574d7281d3d38aa7c89545',\n",
       " 'e5395cc9756d4532b9d1e03eb1494f06',\n",
       " '05fd8f800b39409e8a6430e2bd1f56b5',\n",
       " '570f6b92db9c43eab80e2f38d20aa51c',\n",
       " '3f97bc95ff09416fb34ed0d1d9a97375',\n",
       " 'cdabbc5d90ef4f9d9fd2411b168db099',\n",
       " '3ca3464629e34234867e601c5a3c0ab6',\n",
       " '369f641f364848b6b434fb8d49ce4032',\n",
       " 'bcf38070a0b54f1fb988951cbaa46d5e',\n",
       " '0aa93a726dad47b18825fda62b176603',\n",
       " 'b22523e0aed14a4dbd1b699043a6756f',\n",
       " '218b581683ae4a71882d87a64577d814',\n",
       " 'f789ab6fef1344ecb2308045d3d31e9d',\n",
       " 'ac03bd13a84f46efb84fe99bf5fbc3d1',\n",
       " 'd8618bf4cd9645189b248d5f88695d78',\n",
       " '931503c0212346b7957f2bb883d54993',\n",
       " 'cd8e1a779f734f1d9c029eb73d8e4766',\n",
       " 'c660f0b02721433781141e78b30f39c5',\n",
       " '7377ae4049904a8cbbe7d86f1598fada',\n",
       " '2ecab61a30ae4d26be3475f0d453e10a',\n",
       " '8d922a0a5de54d8c98e4139438e36f80',\n",
       " '9a7e04d1bdd645ebad42d97e3cb62c69',\n",
       " '429100b4e25d4b9d84a8ed3c1ea019bc',\n",
       " '5601b1294eb541acb918bc9de5ef5434',\n",
       " '4f41407c50f64fdc8e0c71cce9ae928e',\n",
       " '9d04b2d3440f4a50bfd2a3ae291e784d',\n",
       " 'f403df35d69140598c6fa9878e39f0c6',\n",
       " '1f460b11324a401cb3d65de01d172619',\n",
       " 'f07230d0ab204df68e80619ee311bb8f',\n",
       " 'e65fa6a6f26f45fea1eb2524579f31dd',\n",
       " 'eaa18a0709924e4da9f5ade783540d65',\n",
       " 'b9154349d7c94ae7ab81c53bd7346fe2',\n",
       " '713a8323fa414409832a7c6d87c83681',\n",
       " '2a324d1355dd42f58e9756baa478ac67',\n",
       " '0327719e76414608858682d19afd9959',\n",
       " 'dcfbe6dc6e4e4c49bee828e54ff5d17f',\n",
       " '03373093185848d7b89d2bdb029e851d',\n",
       " '21c184ef7863440ba795639914b5a86e',\n",
       " '5416683063a14f2b94a14373c9910d3f',\n",
       " '6eb8c6c090804f6bafc4532170cb052d',\n",
       " '1a4f165258ad46edafc7f937bd46196e',\n",
       " '81373254ff29485babbd320170b9d8ab',\n",
       " 'db3587e48d644830a788fc6d2f7a9c54',\n",
       " 'bbb049e0cdee4102a28b3c8c5eba8c6a',\n",
       " '2a62587248a14ec2a2b9d94a79dc769c',\n",
       " '882d550855c04ed5b98b8cc68cc04363',\n",
       " 'ab92ce6201e44a7da9cb0d90a148a2f0',\n",
       " '5e4aafdbbe6e42e298cb818e1b12a01f',\n",
       " '00539de969db4cf29f8456057c9ba923',\n",
       " '3b5d86e4def84b2f84c366b76a14fa11',\n",
       " '7ef5ba0a337d4eb4a21100a41c398c59',\n",
       " '056537f9be414c789565b06478b69108',\n",
       " '620fccc01585415399e5cc5b01fde5a0',\n",
       " '1e9470e7b09a43cda98d2dfce6cd0376',\n",
       " 'e13e58c4ae954c09a19f46f0dcdeb47f',\n",
       " 'a985d28215434db988acfb6f9ab55a86',\n",
       " '3cdccf60ae5a45ac8ac69761bffdc32c',\n",
       " '93bf92e6c662480fb35d4e1e02f8e905',\n",
       " 'e09bc1f0174f4e63bb3eb25b188f871e',\n",
       " '860d93a04f9c4cc8ad2df23c7ca7d537',\n",
       " '954f605084f147ca9e250ad7a703a952',\n",
       " 'e0ce127ca1354a1aa9e6b770f27a526e',\n",
       " '9fdd87b204694b1bb8465ca87ee5b44b',\n",
       " 'fd7ded28534a416fa712a2d4b9a0779b',\n",
       " '0e9caa81a87740f9b74cd2b54315b04f',\n",
       " 'ad38e6f1cfec4d08a7a22afa0ae4f478',\n",
       " '973e5663e2ad491f85dc64907ff3f17e',\n",
       " '8e23be19ebc44c49b128dae5466db0d3',\n",
       " '2aa2f4fb483145bcb43df7fd2ca8279b',\n",
       " 'a5019d3291f54cd78718722e8f2c712d',\n",
       " 'b03218c1ed1845138fa6b3cfbaf6c6dc',\n",
       " '3304855e5b8b40e1842472a294898eb3',\n",
       " '3c34c7a7f6ac4e1ba565b22ba513616b',\n",
       " '4e5b7cd6324244fbba44156ca0d99115',\n",
       " '0d6d5341adc74edb8d0bf088a48fb757',\n",
       " '585424f37b5647459c143631701378d0',\n",
       " 'c796a5688a3141559c745bba7214f7b3',\n",
       " '9606bf9d22954107aa65f064f17d8c77',\n",
       " '33eeb01a7f1a4c83a76ded50b99d24bf',\n",
       " 'c6d140637ef74a0e8994c14163be6448',\n",
       " 'fc7871bbb5ae401fb84166be5a6633ec',\n",
       " 'bc46396674f14803ade0a425af06b577',\n",
       " '69af797126464e239251e03665cc9b6f',\n",
       " 'b36dc23163294fc0aa0003a3065c7ceb',\n",
       " 'd066d1575ea84c848bc5bbb3bc3e2d6e',\n",
       " 'e4230d953d9441cd9ff45b47db2fd502',\n",
       " '82ce32c5cd3249e18523dc96beb28769',\n",
       " '2b6741210b214bee9a3c9e81637ff8d5',\n",
       " 'aeb10505413d4c1eadc71fcbd9735fad',\n",
       " '1c381ac47f1a47da83f226af998f6dd1',\n",
       " 'bb610d5a39f8479a9548cea85de0b51d',\n",
       " '33a891ed899d456baca29567f1849ac0',\n",
       " '939ca76500e64d0787baa636e06e1c50',\n",
       " '80775a038f4144799bf5cc07e998a498',\n",
       " '394ccbfc185741b8adf50d1bc0664e49',\n",
       " '73503f8aee474037b777a4673219b2a8',\n",
       " 'd4a8f48afd264aef87e70f02efdeb599',\n",
       " 'caf9dff635b8440ebb7cda62ceb89dd0',\n",
       " '3cdb1de2f0b44d719aa492bd5a9879a9',\n",
       " '726db76c4090444c83da618b71fcd6f7',\n",
       " '025a02031b754b298bb8bc37559aefc0',\n",
       " '6249c6b2d8b34cfea9ea809424f3517a',\n",
       " 'c4e14b15c1104cb0b32eef42ab20d35a',\n",
       " '622d63907c5b463d92cd3ac33d2ee371',\n",
       " '21c3d7fdaca0465990ee4b05810dfab3',\n",
       " 'ebb49a8007e349278700214308ebabf4',\n",
       " 'e4d9fd52d2f44b8cb5aedbb0f25036da',\n",
       " '14e82320f4544c7ab454f54c2101f96c',\n",
       " '7680095570e64e10a1854a03bb8954d4',\n",
       " 'fd72cfb4d739492a8abd26c15ea44050',\n",
       " 'f49a33c957ba4f4c89cbeb006e4ac1ca',\n",
       " '9608324e651340099e67b3a9c98c54a4',\n",
       " 'c5de4ae38e264a5cba633b3e8765738d',\n",
       " 'f63cfe12a7544933ac64a138b490e92a',\n",
       " '7bce287255444ca1937cd13da86038bf',\n",
       " '1cd13f57662748ff89f58be5870b16f7',\n",
       " 'f72f188169ea47c2a3853190271225c8',\n",
       " '734843cf04eb4d93a5f85fdad91bb780',\n",
       " '2e705bbf3d8c4adfb8c7003ed87213f7',\n",
       " '6f0d48b291ec4d28a4fb9169f972788b',\n",
       " 'a1b6e5af20ef4b47bcc64b337210b1fc',\n",
       " '8c6797c54aa14c8ba438a3fd1cd3fc1f',\n",
       " 'e4dc037e8dc3465da0064ceb1e0c255d',\n",
       " '1e8dcd1b93da465b99b73d18edd7ed72',\n",
       " '1c833e62612b4a409e9b39ee51f3416f',\n",
       " '39d8b8eb1d75445785e601ced9e95143',\n",
       " 'e0026559f4834b8b9ca73abaf1a2aee5',\n",
       " 'd7a6ca9f76044daf8048321d03a7fe75',\n",
       " '3f6b1c88e6684485b75f8c14406681eb',\n",
       " '8a65bd89a3bf4857b84e25c47555746e',\n",
       " 'e76861203943446e8863e978106b10b9',\n",
       " '1f1e96376d5d42268b4efc0dc4b001fe',\n",
       " '24e0847d06744898a397df588f65f791',\n",
       " '2a908ba51430426a8486aa3de232cbe8',\n",
       " 'fa615ba31837499b82d8f70aa281ccc5',\n",
       " 'df27b61729854d2a837617aaa942b389',\n",
       " '984463f8e7994fc4964b2ec21e0f5fd2',\n",
       " 'b88af814b9c843059a181a85adbbf3a3',\n",
       " 'dbdecb5b814947c39a485554557b8c43',\n",
       " '07fa7efecac6424b9e8e4d6d20eb3141',\n",
       " '5f84848952f74c5e88140716ddefab49',\n",
       " 'cc4dfbc1f7974ca9b1fdb7257e3d524f',\n",
       " 'f1097a8c569940b8ae77ac486c2d021f',\n",
       " '6502c2f784db433486b1719310080626',\n",
       " '48bafa3031dc40b999f77fd1206dabdb',\n",
       " '0a6134e80b524445a8aefff076df211d',\n",
       " 'b4f4f474195947599d1800152bbdeedf',\n",
       " 'aa3844f0891c4cbfa824db689c4aacbd',\n",
       " '637664cfc84f4d17acbcdac881c3bbbd',\n",
       " 'd3bc8ac340ae413baa85d7849ae9f215',\n",
       " '7655c94453a344f0964881028cd8994e',\n",
       " '8e31168410fb4cfba4db57afdbeb9ecd',\n",
       " 'f274cf6e80be4097851ec431a4c227ae',\n",
       " 'c6dc2dad833e4c5a908fd41984bb43a4',\n",
       " 'f42508f0fae04f9ab947ef5ef437ffa2',\n",
       " 'f434ff73553f4d9bb40edb762b59d169',\n",
       " '0883b7618ec543a9b85dba7875d57dfc',\n",
       " '7561c1c746504b4fbce2d0cc755b2b8a',\n",
       " 'c3f879276f164f7db059667ccff7df01',\n",
       " 'dca981c3b8b64c21a4e496be480c35de',\n",
       " '452f83fdbd2c46f584d228a35b9823f7',\n",
       " '13dd579c18984411a9fe76dc46a96fee',\n",
       " '1a4b09bde5b74dcbb98adac6f99b1974',\n",
       " '86708e7dd44c4b17bdae81f73f2a8c34',\n",
       " 'da67b80f256f4cabaef441f62ec7e253',\n",
       " '491b24ae9ef64d4aa3d856ac7041db1b',\n",
       " 'e2d09b6e52ab4fcebcd0aff9ebd5eb6f',\n",
       " '00d465c4428d4d2fb09a0037d055d2aa',\n",
       " '0a9eea42e06d4bc1a7e099a093c97098',\n",
       " 'cdcd429407ad44d69bdb1d9b5c37b176',\n",
       " '6d4ba00dc310472cbc0cb7fa444c414a',\n",
       " 'bb6fe44b79984a7987edbc61203bf68f',\n",
       " '1f3f8804c232478f947e9bea5f282d25',\n",
       " '03bd5a2302e1435f8c8c815669a3f636',\n",
       " '8d6c212869064205b725602e0dd3155c',\n",
       " 'db8b38e362f9476b8a3650ec61e6a130',\n",
       " '34c9749d30d7480995c415e93a8a023c']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(\":memory:\")\n",
    "client.get_collections()\n",
    "\n",
    "with open('sklearn.tree.txt', 'r', encoding='utf-8') as file:\n",
    "    documents = file.readlines()\n",
    "\n",
    "# Remove newline characters from each document\n",
    "documents = [doc.strip() for doc in documents]\n",
    "\n",
    "# Now, add the documents to the Qdrant client\n",
    "client.add(\n",
    "    collection_name=\"knowledge-base\",\n",
    "    documents=documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Set the OPENAI_API_KEY environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Replace with your actual API key\n",
    "\n",
    "async_ai = AsyncOpenAI()\n",
    "\n",
    "async def rag( chat_history: list[str], question: str,  n_points: int = 3) -> str:\n",
    "    results = client.query(\n",
    "        collection_name=\"knowledge-base\",\n",
    "        query_text=question,\n",
    "        limit=n_points,\n",
    "    )\n",
    "    \n",
    "    context = \"\\n\".join(r.document for r in results)\n",
    "\n",
    "    metaprompt = f\"\"\"\n",
    "    You are a helpful machine learning bot.\n",
    "    Answer the following question using the provided context.\n",
    "    Also refer to the chat history while answering a question. consider info given by the assisstant only as truth.\n",
    "    The context provided is only documentation for referring information. When asked direct questions about model building remember answers in the chat history and when asked factual question about the docs explicitly, refer to the context documentation. \n",
    "    If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "    If you have limited information on something, state is and then answer \"this is all I know.\" irrespective of how much their word count expectation is.\n",
    "\n",
    "    Question: {question}\n",
    "    CHAT HISTORY : {chat_history}\n",
    "    Context:\n",
    "    {context.strip()}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    completion = await async_ai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": metaprompt},\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "The DecisionTreeClassifier class in scikit-learn has various parameters that can be used to modify the behavior of the decision tree model. Here are some commonly used parameters for the DecisionTreeClassifier:\n",
      "- criterion: This parameter determines the function used to measure the quality of a split. The two options are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      "- splitter: This parameter determines the strategy used to choose the split at each node. The two options are \"best\" for the best split and \"random\" for a random split.\n",
      "- max_depth: This parameter sets the maximum depth of the decision tree. A higher value can lead to overfitting, while a lower value can lead to underfitting.\n",
      "- min_samples_split: This parameter sets the minimum number of samples required to split an internal node. A lower value can lead to overfitting, while a higher value can prevent the tree from splitting further.\n",
      "- min_samples_leaf: This parameter sets the minimum number of samples required to be at a leaf node. A lower value can lead to overfitting, while a higher value can prevent the tree from expanding further.\n",
      "- max_features: This parameter sets the maximum number of features to consider when looking for the best split. It can be a fixed number or a percentage of the total features.\n",
      "- class_weight: This parameter assigns weights to different classes. It can be used to handle class imbalance issues.\n",
      "- random_state: This parameter sets the random seed for reproducibility.\n",
      "\n",
      "Please note that these are just some of the parameters available for the DecisionTreeClassifier. There may be additional parameters depending on the version of scikit-learn.\n"
     ]
    }
   ],
   "source": [
    "print(await rag([] , \"What all are the parameters for decision tree?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sklearn.tree.DecisionTreeClassifier is a class in the scikit-learn library that implements a decision tree classifier. It is used for classification tasks in machine learning. Decision trees are a type of supervised learning algorithm that can be used for both classification and regression tasks.\n"
     ]
    }
   ],
   "source": [
    "print(await rag([],\"What is svm?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the answer to this question as there is no information provided about photosynthesis in the context documentation.\n"
     ]
    }
   ],
   "source": [
    "print(await rag([],\"what is photosynthesis?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(await rag(\"Explain everything you know about machine learning?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='bc4c57b8-d1fa-4f87-acc2-0ee21efcddbc'>\n",
       "  <div id=\"f6678640-c7fd-4edd-bb32-4f7f544e9a8b\" data-root-id=\"bc4c57b8-d1fa-4f87-acc2-0ee21efcddbc\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"c057dc43-01ac-4a02-92f5-525cf6a69cef\":{\"version\":\"3.2.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"bc4c57b8-d1fa-4f87-acc2-0ee21efcddbc\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"69c0bcdb-ea08-4198-bbc2-b16fd75771e1\",\"attributes\":{\"plot_id\":\"bc4c57b8-d1fa-4f87-acc2-0ee21efcddbc\",\"comm_id\":\"ea54c43731a84b76b41e3ccba8d12c50\",\"client_comm_id\":\"fa043babc4c643588cb12150ec1a0948\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"c057dc43-01ac-4a02-92f5-525cf6a69cef\",\"roots\":{\"bc4c57b8-d1fa-4f87-acc2-0ee21efcddbc\":\"f6678640-c7fd-4edd-bb32-4f7f544e9a8b\"},\"root_ids\":[\"bc4c57b8-d1fa-4f87-acc2-0ee21efcddbc\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "bc4c57b8-d1fa-4f87-acc2-0ee21efcddbc"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c37d59f535642ba8d06e59f4316dba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'76bc7749-7d83-44fe-90fd-4a0cd74c6da0': {'version"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.application:Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOMainLoop object at 0x107db4410>>, <Task finished name='Task-5' coro=<ParamMethod._eval_async() done, defined at /Users/snehadharne/anaconda3/lib/python3.11/site-packages/panel/param.py:815> exception=TypeError(\"rag() missing 1 required positional argument: 'question'\")>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
      "    ret = callback()\n",
      "          ^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/tornado/ioloop.py\", line 762, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/panel/param.py\", line 838, in _eval_async\n",
      "    raise e\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/panel/param.py\", line 835, in _eval_async\n",
      "    self._update_inner(await awaitable)\n",
      "                       ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/param/_async.py\", line 11, in _depends\n",
      "    return await func(*args, **kw)  # noqa: E999\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/panel/depends.py\", line 244, in wrapped\n",
      "    return await evaled\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3925370243.py\", line 5, in collect_messages\n",
      "    response = await rag( chat_history)\n",
      "                    ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: rag() missing 1 required positional argument: 'question'\n"
     ]
    }
   ],
   "source": [
    "async def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    query.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = await rag( chat_history) \n",
    "    chat_history.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    chat_history.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    response = await rag(context, chat_history) \n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)\n",
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "query = []\n",
    "panels = [] # collect display \n",
    "\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Transformers chatbot! Type done when you want run the model. Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/1718345190.py:20: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(lambda change: asyncio.create_task(on_submit(change)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef15e86b901b40ac9f0b716889f6f630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Please enter your question:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2addacbfec18481c9b144b2423b0a3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> what is gini index?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdd1c9b826b4b8d9d5af83c24f0edf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> [\\'The Gini index is a measure of impurity or inequality"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "async def on_submit(_):\n",
    "    question = input_box.value\n",
    "    \n",
    "    \n",
    "    response = await asyncio.gather(rag(question, chat_history))\n",
    "    chat_history.append({'role':'user', 'content':f\"{question}\"})\n",
    "    chat_history.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    input_box.value = \"\"\n",
    "    display(widgets.HTML(f'<b>User:</b> {question}'))\n",
    "    display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {response}'))\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "print(\"Welcome to the Transformers chatbot! Type done when you want run the model. Type 'exit' to stop.\")\n",
    "\n",
    "input_box = widgets.Text(placeholder='Please enter your question:')\n",
    "input_box.on_submit(lambda change: asyncio.create_task(on_submit(change)))\n",
    "\n",
    "display(input_box)\n",
    "\n",
    "await asyncio.gather(asyncio.sleep(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'what is gini index?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"['The Gini index is a metric used in decision tree algorithms to measure the impurity or inequality of a node. It calculates the probability of incorrectly classifying a randomly chosen element if it were randomly labeled according to the distribution of labels in the node. The Gini index ranges from 0 to 1, where a value of 0 represents a perfectly pure node and a value of 1 represents a completely impure node.']\"},\n",
       " {'role': 'user', 'content': 'i used breast-cancer-wisconsin dataset'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"['The Gini index is a metric used in decision tree algorithms to measure the impurity or inequality of a node. It calculates the probability of incorrectly classifying a randomly chosen element if it were randomly labeled according to the distribution of labels in the node. The Gini index ranges from 0 to 1, where a value of 0 represents a perfectly pure node and a value of 1 represents a completely impure node.']\"},\n",
       " {'role': 'user', 'content': 'which dataset did I use?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"['The Gini index is a metric used in decision tree algorithms to measure the impurity or inequality of a node. It calculates the probability of incorrectly classifying a randomly chosen element if it were randomly labeled according to the distribution of labels in the node. The Gini index ranges from 0 to 1, where a value of 0 represents a perfectly pure node and a value of 1 represents a completely impure node.']\"},\n",
       " {'role': 'user', 'content': 'what should i set the value for criterion?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"['You used the breast-cancer-wisconsin dataset.']\"}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "def to_numeric(F6):\n",
    "    if F6 == \"?\":\n",
    "        return np.nan\n",
    "    else:\n",
    "        return int(F6)\n",
    "\n",
    "def file_preprocess(filename):\n",
    "  df = pd.read_csv(filename)\n",
    "  df['F6'] = df['F6'].apply(to_numeric)\n",
    "  mean_F6 = df['F6'].mean()\n",
    "  df['F6'] = df['F6'].fillna(mean_F6)\n",
    "  return df\n",
    "def runner(json_file):\n",
    "  # Load parameters from JSON\n",
    "  with open(json_file, 'r') as file:\n",
    "      parameters = json.load(file)\n",
    "\n",
    "  model_name = parameters['model_name']\n",
    "  df = file_preprocess(parameters['filename'])\n",
    "\n",
    "  #Check for target_variable is present or not\n",
    "  target_variable = parameters.get(\"target_variable\", None)\n",
    "  if target_variable is None:\n",
    "      raise ValueError(\"Target variable not specified in the parameters.\")\n",
    "\n",
    "  X = df.drop(columns=[target_variable])\n",
    "  y = df[target_variable]\n",
    "\n",
    "  # Define default parameters for SVMClassifier\n",
    "  default_lr_parameters = {\n",
    "      \"penalty\": 'l2',\n",
    "      \"dual\": False,\n",
    "      \"tol\": 0.0001,\n",
    "      \"C\": 1.0,\n",
    "      \"fit_intercept\": True,\n",
    "      \"intercept_scaling\": 1,\n",
    "      \"class_weight\": None,\n",
    "      \"random_state\": None,\n",
    "      \"solver\": 'lbfgs',\n",
    "      \"max_iter\": 100,\n",
    "      \"multi_class\": 'auto',\n",
    "      \"verbose\": 0,\n",
    "      \"warm_start\": False,\n",
    "      \"n_jobs\": None,\n",
    "      \"l1_ratio\": None\n",
    "  }\n",
    "  default_svm_parameters = {\n",
    "    'C': 1.0,\n",
    "    'kernel': 'rbf',\n",
    "    'degree': 3,\n",
    "    'gamma': 'scale',\n",
    "    'coef0': 0.0,\n",
    "    'shrinking': True,\n",
    "    'probability': False,\n",
    "    'tol': 0.001,\n",
    "    'cache_size': 200,\n",
    "    'class_weight': None,\n",
    "    'verbose': False,\n",
    "    'max_iter': -1,\n",
    "    'decision_function_shape': 'ovr',\n",
    "    'break_ties': False,\n",
    "    'random_state': None\n",
    "  }\n",
    "  default_decision_tree_parameters = {\n",
    "    \"criterion\": \"gini\",\n",
    "    \"splitter\": \"best\",\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_features\": None,\n",
    "    \"random_state\": None,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    \"class_weight\": None,\n",
    "    \"ccp_alpha\": 0.0\n",
    " }\n",
    "\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=parameters['split'], random_state=42)\n",
    "\n",
    "  def_param = {\n",
    "      \"decision_tree\" : {\"param_dict\" : \"default_decision_tree_parameters\", \"lib_name\" : \"DecisionTreeClassifier\"},\n",
    "      \"svm\" : {\"param_dict\" : \"default_decision_tree_parameters\", \"lib_name\" : \"DecisionTreeClassifier\"},\n",
    "      \"lr\" : {\"param_dict\" : \"default_decision_tree_parameters\", \"lib_name\" : \"LogisticRegression\"}\n",
    "  }\n",
    "\n",
    "  param = def_param[model_name][\"param_dict\"]\n",
    "  lib_name = def_param[model_name][\"lib_name\"]\n",
    "  # print(param, lib_name)\n",
    "\n",
    "  # Merge default and user-provided parameters\n",
    "  merged_parameters = {**eval(param), **parameters.get(\"param\", {})}\n",
    "  # print(merged_parameters)\n",
    "\n",
    "  # Initialize the Decision Tree model with the merged parameters\n",
    "  model = eval(lib_name)(**merged_parameters)\n",
    "\n",
    "  # Train the Decision Tree model\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Make predictions on the test set\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print(f\"Accuracy: {accuracy}\")\n",
    "  return accuracy\n",
    "#   print(merged_parameters)\n",
    "  # print(param)\n",
    "  # print(eval(param))\n",
    "  # print(parameters[\"param\"])\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import json\n",
    "# def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "#     messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=model,\n",
    "#         messages=messages,\n",
    "#         temperature=0, # this is the degree of randomness of the model's output\n",
    "#     )\n",
    "\n",
    "async def completion1(prompt):\n",
    "    completion = await async_ai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= prompt,\n",
    "    temperature = 0)\n",
    "    return(completion.choices[0].message.content) \n",
    "\n",
    "   \n",
    "async def make_json(chat_history1):\n",
    "    prompt = f\"\"\"\n",
    "    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \n",
    "    include 'target_variable' as mentioned in the prompt. and 'split' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\n",
    "    [\n",
    "    \n",
    "    \"filename\" : \"breast-cancer-wisconsin.csv\",\n",
    "    \"model_name\" : \"decision_tree\",\n",
    "    \"param\": [\n",
    "        \"kernel\": \"linear\"\n",
    "    ],\n",
    "    \"target_variable\": \"Class\",\n",
    "    \"split\" : 0.2\n",
    "    ]\n",
    "    text = ```{chat_history1}```\n",
    "    \"\"\"\n",
    "    json_objects = await completion1(prompt)\n",
    "    print(json_objects)\n",
    "    data_dict = json.loads(json_objects)\n",
    "    json_file_path = \"sample.json\"\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(data_dict, json_file,indent=2)\n",
    "    result = runner(\"sample.json\")\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Transformers chatbot! Type done when you want run the model. Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3627884150.py:24: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(lambda change: asyncio.create_task(on_submit(change)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df26575658ed400cbf867593895b4501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Please enter your question:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c11d824797425ead22760996765982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> what is gini index?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7e52737d4943b1886917a655274609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> [\\'The Gini index is a measurement of impurity or inequa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809ad43d77714ae183e33563a167b799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> build a model for decision tree classifier with breast-cancer-wisconsin dataset and r"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a539760ce0024ecfa3c93a3754663e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> [\\'The Gini index is a measurement of impurity or inequa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb309d3974004b659adb3727b80a58f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> build a model for decision tree classifier with breast-cancer-wisconsin dataset and r"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8976750c3f0a438cbe96c1abc06e4815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> [\\'The Gini index is a measurement of impurity or inequa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-52' coro=<on_submit() done, defined at /var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3627884150.py:4> exception=BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \\'\\\\\\'\\\\\\\\n    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \\\\\\\\n    include \\\\\\\\\\\\\\'target_variable\\\\\\\\\\\\\\' as mentioned in the prompt. and \\\\\\\\\\\\\\'split\\\\\\\\\\\\\\' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\\\\\\\\n    [\\\\\\\\n    \\\\\\\\n    \"filename\" : \"breast-cancer-wisconsin.csv\",\\\\\\\\n    \"model_name\" : \"decision_tree\",\\\\\\\\n    \"param\": [\\\\\\\\n        \"kernel\": \"linear\"\\\\\\\\n    ],\\\\\\\\n    \"target_variable\": \"Class\",\\\\\\\\n    \"split\" : 0.2\\\\\\\\n    ]\\\\\\\\n    text = ```[{\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'what is gini index?\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}]```\\\\\\\\n    \\\\\\' is not of type \\\\\\'array\\\\\\' - \\\\\\'messages\\\\\\'\\', \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3627884150.py\", line 8, in on_submit\n",
      "    accuracy = await make_json(chat_history)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3298584788.py\", line 151, in make_json\n",
      "    json_objects = await completion1(prompt)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3298584788.py\", line 128, in completion1\n",
      "    completion = await async_ai.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1474, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1275, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1318, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': '\\'\\\\n    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \\\\n    include \\\\\\'target_variable\\\\\\' as mentioned in the prompt. and \\\\\\'split\\\\\\' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\\\\n    [\\\\n    \\\\n    \"filename\" : \"breast-cancer-wisconsin.csv\",\\\\n    \"model_name\" : \"decision_tree\",\\\\n    \"param\": [\\\\n        \"kernel\": \"linear\"\\\\n    ],\\\\n    \"target_variable\": \"Class\",\\\\n    \"split\" : 0.2\\\\n    ]\\\\n    text = ```[{\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'what is gini index?\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}, {\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}, {\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}]```\\\\n    \\' is not of type \\'array\\' - \\'messages\\'', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-54' coro=<on_submit() done, defined at /var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3627884150.py:4> exception=BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \\'\\\\\\'\\\\\\\\n    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \\\\\\\\n    include \\\\\\\\\\\\\\'target_variable\\\\\\\\\\\\\\' as mentioned in the prompt. and \\\\\\\\\\\\\\'split\\\\\\\\\\\\\\' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\\\\\\\\n    [\\\\\\\\n    \\\\\\\\n    \"filename\" : \"breast-cancer-wisconsin.csv\",\\\\\\\\n    \"model_name\" : \"decision_tree\",\\\\\\\\n    \"param\": [\\\\\\\\n        \"kernel\": \"linear\"\\\\\\\\n    ],\\\\\\\\n    \"target_variable\": \"Class\",\\\\\\\\n    \"split\" : 0.2\\\\\\\\n    ]\\\\\\\\n    text = ```[{\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'what is gini index?\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}]```\\\\\\\\n    \\\\\\' is not of type \\\\\\'array\\\\\\' - \\\\\\'messages\\\\\\'\\', \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3627884150.py\", line 8, in on_submit\n",
      "    accuracy = await make_json(chat_history)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3298584788.py\", line 151, in make_json\n",
      "    json_objects = await completion1(prompt)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3298584788.py\", line 128, in completion1\n",
      "    completion = await async_ai.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1474, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1275, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1318, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': '\\'\\\\n    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \\\\n    include \\\\\\'target_variable\\\\\\' as mentioned in the prompt. and \\\\\\'split\\\\\\' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\\\\n    [\\\\n    \\\\n    \"filename\" : \"breast-cancer-wisconsin.csv\",\\\\n    \"model_name\" : \"decision_tree\",\\\\n    \"param\": [\\\\n        \"kernel\": \"linear\"\\\\n    ],\\\\n    \"target_variable\": \"Class\",\\\\n    \"split\" : 0.2\\\\n    ]\\\\n    text = ```[{\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'what is gini index?\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}, {\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}, {\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}]```\\\\n    \\' is not of type \\'array\\' - \\'messages\\'', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-56' coro=<on_submit() done, defined at /var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3627884150.py:4> exception=BadRequestError('Error code: 400 - {\\'error\\': {\\'message\\': \\'\\\\\\'\\\\\\\\n    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \\\\\\\\n    include \\\\\\\\\\\\\\'target_variable\\\\\\\\\\\\\\' as mentioned in the prompt. and \\\\\\\\\\\\\\'split\\\\\\\\\\\\\\' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\\\\\\\\n    [\\\\\\\\n    \\\\\\\\n    \"filename\" : \"breast-cancer-wisconsin.csv\",\\\\\\\\n    \"model_name\" : \"decision_tree\",\\\\\\\\n    \"param\": [\\\\\\\\n        \"kernel\": \"linear\"\\\\\\\\n    ],\\\\\\\\n    \"target_variable\": \"Class\",\\\\\\\\n    \"split\" : 0.2\\\\\\\\n    ]\\\\\\\\n    text = ```[{\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'what is gini index?\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'user\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\\\\\\\\\'}, {\\\\\\\\\\\\\\'role\\\\\\\\\\\\\\': \\\\\\\\\\\\\\'assistant\\\\\\\\\\\\\\', \\\\\\\\\\\\\\'content\\\\\\\\\\\\\\': \"[\\\\\\\\\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\\\\\\\\\']\"}]```\\\\\\\\n    \\\\\\' is not of type \\\\\\'array\\\\\\' - \\\\\\'messages\\\\\\'\\', \\'type\\': \\'invalid_request_error\\', \\'param\\': None, \\'code\\': None}}')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3627884150.py\", line 8, in on_submit\n",
      "    accuracy = await make_json(chat_history)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3298584788.py\", line 151, in make_json\n",
      "    json_objects = await completion1(prompt)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/ck/hmsclsfj6y1d_pbb28pqpv_h0000gn/T/ipykernel_38183/3298584788.py\", line 128, in completion1\n",
      "    completion = await async_ai.chat.completions.create(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1199, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1474, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1275, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/snehadharne/anaconda3/lib/python3.11/site-packages/openai/_base_client.py\", line 1318, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': '\\'\\\\n    read the chat history between the user and the chatbot and create a dictionary of the model parameters finalized by them. include filename and append the dataset filename with .csv extension. create  a dictionary named param (which would be the parameters of the model) and write all the parameters asked by the user in the datatype of what the function requires. \\\\n    include \\\\\\'target_variable\\\\\\' as mentioned in the prompt. and \\\\\\'split\\\\\\' should be 0.2 unless some other value is specified. an example for svm model might look like this (with curly brackets instead of sqauare brackets) also make sure you write the model name compatible to the sklearn libraries:\\\\n    [\\\\n    \\\\n    \"filename\" : \"breast-cancer-wisconsin.csv\",\\\\n    \"model_name\" : \"decision_tree\",\\\\n    \"param\": [\\\\n        \"kernel\": \"linear\"\\\\n    ],\\\\n    \"target_variable\": \"Class\",\\\\n    \"split\" : 0.2\\\\n    ]\\\\n    text = ```[{\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'what is gini index?\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}, {\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}, {\\\\\\'role\\\\\\': \\\\\\'user\\\\\\', \\\\\\'content\\\\\\': \\\\\\'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy\\\\\\'}, {\\\\\\'role\\\\\\': \\\\\\'assistant\\\\\\', \\\\\\'content\\\\\\': \"[\\\\\\'The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.\\\\\\']\"}]```\\\\n    \\' is not of type \\'array\\' - \\'messages\\'', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "async def on_submit(_):\n",
    "    question = input_box.value\n",
    "    \n",
    "    if question == 'done':\n",
    "        accuracy = await make_json(chat_history)\n",
    "        chat_history.append({'role':'user', 'content':\"what is the accuracy?\"})\n",
    "        chat_history.append({'role':'assistant', 'content':\"the accuracy is\"+f\"{accuracy}\"})\n",
    "\n",
    "    response = await asyncio.gather(rag(question, chat_history))\n",
    "    chat_history.append({'role':'user', 'content':f\"{question}\"})\n",
    "    chat_history.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    input_box.value = \"\"\n",
    "    display(widgets.HTML(f'<b>User:</b> {question}'))\n",
    "    display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {response}'))\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "print(\"Welcome to the Transformers chatbot! Type done when you want run the model. Type 'exit' to stop.\")\n",
    "\n",
    "input_box = widgets.Text(placeholder='Please enter your question:')\n",
    "input_box.on_submit(lambda change: asyncio.create_task(on_submit(change)))\n",
    "\n",
    "display(input_box)\n",
    "\n",
    "await asyncio.gather(asyncio.sleep(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'what is gini index?'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"['The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.']\"},\n",
       " {'role': 'user',\n",
       "  'content': 'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"['The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.']\"},\n",
       " {'role': 'user',\n",
       "  'content': 'build a model for decision tree classifier with breast-cancer-wisconsin dataset and return the accuracy'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"['The Gini index is a measurement of impurity or inequality in a given set of data. It is commonly used in decision tree algorithms to evaluate the quality of a split. The Gini index ranges from 0 to 1, where 0 represents perfect equality (all elements belong to the same class) and 1 represents perfect inequality (all elements belong to different classes). A lower Gini index indicates a better split.']\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8fd72f3a6c4077961c960bc922d10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>User:</b> what is decision tree classfier?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121a87efa5f64d0185960446da29deb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b><font color=\"blue\">Chatbot:</font></b> [\\'The Gini index is a measure of impurity used in decis"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
